<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <title>RLC 2025 - Week of August 3</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Rubik:ital,wght@0,300..900;1,300..900&display=swap"
    rel="stylesheet">
  <link
    href="https://fonts.googleapis.com/css2?family=Bai+Jamjuree:wght@200..700&family=Rubik:ital,wght@0,300..900;1,300..900&display=swap"
    rel="stylesheet">
  <link href="build.css" rel="stylesheet">
  <link rel="icon" type="image/png" href="/favicon-48x48.png" sizes="48x48" />
  <link rel="icon" type="image/svg+xml" href="/favicon.svg" />
  <link rel="shortcut icon" href="/favicon.ico" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <meta name="apple-mobile-web-app-title" content="RLC" />
  <link rel="manifest" href="/site.webmanifest" />
</head>

<body class="bg-rlgrey font-rubik text-rldarkblue-900 p-6">
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- Include Menu -->
  <script src="jquery.js"></script>
  <script src="data.js"></script>

  <div class="container mx-auto">
    <div class="flex flex-col min-h-screen justify-between">
      <div>
        <div class="m-2 grid grid-cols-3 items-center rounded-md mt-4 p-2 border-0 border-rldarkblue-900">
          <div class="p-2 w-full rounded-md">
            <div class="hidden lg:block max-w-60">
              <a href="index.html"><img alt="Company logo" src="data/logos/rlc-logo.svg" /></a>
            </div>
            <div class="block pt-1 lg:hidden max-w-60">
              <a href="index.html"><img alt="Company logo" src="data/logos/rlc-logo.svg" /></a>
            </div>
          </div>
          <div></div>
          <div id="largeMenu" class="p-2 m-1 w-full hidden lg:block rounded-md"></div>
          <div id="collapsedMenu" class="p-2 m-1 w-full block lg:hidden rounded-md">
            <div class="relative flex flex-row-reverse">
              <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                stroke="currentColor"
                class="size-10 p-1 font-rubik text-xl m-1 text-rldarkblue-900 hover:text-rldarkblue-500 hover:cursor-pointer"
                onclick="showMenu()">
                <path stroke-linecap="round" stroke-linejoin="round"
                  d="M3.75 5.25h16.5m-16.5 4.5h16.5m-16.5 4.5h16.5m-16.5 4.5h16.5" />
              </svg>
              <div id="collapsedMenuItems"
                class="absolute top-10 z-10 hidden w-40 shadow-md bg-rlgrey/100 backdrop-blur-md rounded-md p-4 m-4 grid grid-cols-1 border border-black">
              </div>
            </div>
          </div>
        </div>

        <!-- PAGE TITLE -->
        <h1 class="text-4xl  font-bai text-center text-blue mb-10 mt-10">RLC 2025 Schedule: August 5–9</h1>

        <!-- SCHEDULE -->
        <div class="grid grid-cols-1 lg:grid-cols-2 xl:grid-cols-3 gap-6">
          <div class="bg-rllightblue-50 shadow rounded-lg p-6">
            <h2 class="text-xl font-semibold mb-3 text-blue">Tuesday, August 5</h2>
            <div class="grid grid-cols-3">
              <div class="mb-2 p-1">8:30 AM - 5 PM</div>
              <div class="mb-2 col-span-2 p-1">Coffee and drinks</div>
            </div>
            <div class="grid grid-cols-3">
              <div class="mb-2 p-1">9 AM - 5 PM</div>
              <div class="mb-2 col-span-2 p-1"> <a href="./accepted_workshops.html"
                  class="text-blue hover:text-rldarkblue-500" ">Workshops</a> (8 parallel sessions)</div>
            </div> 
            <div class=" grid grid-cols-3">
                  <div class="mb-2 p-1">12:30 PM - 2 PM</div>
                  <div class="mb-2 col-span-2 p-1">Lunch</div>
              </div>
            </div>

            <!-- Wednesday -->
            <div class=" bg-rllightblue-50 shadow rounded-lg p-6">
              <h2 class="text-xl font-semibold mb-3 text-blue">Wednesday, August 6</h2>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">8:30 AM - 5 PM</div>
                <div class="mb-2 col-span-2 p-1">Coffee and drinks</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">8:45 AM - 9 AM</div>
                <div class="mb-2 col-span-2 p-1">Opening Comments</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">9 AM - 10 AM</div>
                <div class="mb-2 col-span-2 p-1">Keynote: Leslie Kaelbling</div>
              </div>
              <div class="text-center">
                <div class="m-2 p-2 font-semibold">20-minute Break</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">10:20 AM - 11:15 AM</div>
                <div class="mb-2 col-span-2 p-1">Orals (4 parallel sessions)</div>
              </div>
              <div class="text-center">
                <div class="m-2 p-2 font-semibold">30-minute Break</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">11:45 AM - 12:30 PM</div>
                <div class="mb-2 col-span-2 p-1">Orals (4 parallel sessions)</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">12:30 PM - 2 PM</div>
                <div class="mb-2 col-span-2 p-1">Lunch</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">2 PM - 3 PM</div>
                <div class="mb-2 col-span-2 p-1">Keynote: Dale Schuurmans</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">3 PM - 6 PM</div>
                <div class="mb-2 col-span-2 p-1">Poster Session</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">6 PM</div>
                <div class="mb-2 col-span-2 p-1">Banquet (Edmonton Convention Center)</div>
              </div>
            </div>

            <div class="bg-rllightblue-50 shadow rounded-lg p-6">
              <h2 class="text-xl font-semibold mb-3 text-blue">Thursday, August 7</h2>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">8:30 AM - 5 PM</div>
                <div class="mb-2 col-span-2 p-1">Coffee and drinks</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">9 AM - 10 AM</div>
                <div class="mb-2 col-span-2 p-1">Keynote: Joelle Pineau</div>
              </div>
              <div class="text-center">
                <div class="m-2 p-2 font-semibold">20-minute Break</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">10:20 AM - 11:15 AM</div>
                <div class="mb-2 col-span-2 p-1">Orals (4 parallel sessions)</div>
              </div>
              <div class="text-center">
                <div class="m-2 p-2 font-semibold">30-minute Break</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">11:45 AM - 12:30 PM</div>
                <div class="mb-2 col-span-2 p-1">Orals (4 parallel sessions)</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">12:30 PM - 2 PM</div>
                <div class="mb-2 col-span-2 p-1">Lunch</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">2 PM - 3 PM</div>
                <div class="mb-2 col-span-2 p-1">Keynote: Michael Littman</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">3 PM - 6 PM</div>
                <div class="mb-2 col-span-2 p-1">Poster Session</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">6 PM</div>
                <div class="mb-2 col-span-2 p-1">Dinner on your own</div>
              </div>
            </div>

            <!-- Friday -->
            <div class="bg-rllightblue-50 shadow rounded-lg p-6">
              <h2 class="text-xl font-semibold mb-3 text-blue">Friday, August 8</h2>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">8:30 AM - 5 PM</div>
                <div class="mb-2 col-span-2 p-1">Coffee and drinks</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">9 AM - 10 AM</div>
                <div class="mb-2 col-span-2 p-1">Keynote: Peter Dayan</div>
              </div>
              <div class="text-center">
                <div class="m-2 p-2 font-semibold">20-minute Break</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">10:20 AM - 11:15 AM</div>
                <div class="mb-2 col-span-2 p-1">Orals (4 parallel sessions)</div>
              </div>
              <div class="text-center">
                <div class="m-2 p-2 font-semibold">30-minute Break</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">11:45 AM - 12:30 PM</div>
                <div class="mb-2 col-span-2 p-1">Orals (4 parallel sessions)</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">12:30 PM - 2 PM</div>
                <div class="mb-2 col-span-2 p-1">Lunch</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">2:00 PM - 3:00 PM</div>
                <div class="mb-2 col-span-2 p-1">Keynote: Richard S. Sutton</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">3 PM - 6 PM</div>
                <div class="mb-2 col-span-2 p-1">Poster Session</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">6 PM</div>
                <div class="mb-2 col-span-2 p-1">Dinner on your own</div>
              </div>
            </div>

            <div class="bg-rllightblue-50 shadow rounded-lg p-6">
              <h2 class="text-xl font-semibold mb-3 text-blue">Saturday, August 9</h2>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">9 AM - 10 AM</div>
                <div class="mb-2 col-span-2 p-1">Breakfast & Meet-ups</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">10 AM - 11 AM</div>
                <div class="mb-2 col-span-2 p-1">Town Hall</div>
              </div>
              <div class="grid grid-cols-3">
                <div class="mb-2 p-1">11 AM - 1 PM</div>
                <div class="mb-2 col-span-2 p-1">Socials, Meet-ups, Excursions</div>
              </div>
            </div>
          </div>
          <h1 class='text-4xl font-bai text-center text-blue mt-20 p-2 m-2'>Oral Talks</h1>
          <div id="oral_talks">
<h2 class='text-3xl font-bai text-center text-blue m-4 p-4'>Aug 6</h2>
<div class='grid grid-cols-1 md:grid-cols-2 lg:grid-cols-2 gap-4'>
<div class='bg-rllightblue-50 shadow rounded-lg p-6'>
<h3 class='text-xl font-semibold mb-3 text-blue m-2 p-2'>Track 1: RL algorithms</h3>
<ol class='list-decimal p-2 m-2'>
<li class='p-1'>Burning RED: Unlocking Subtask-Driven Reinforcement Learning and Risk-Awareness in Average-Reward Markov Decision Processes</li>
<li class='p-1'>RL$^3$: Boosting Meta Reinforcement Learning via RL inside RL$^2$</li>
<li class='p-1'>Fast Adaptation with Behavioral Foundation Models</li>
<li class='p-1'>Understanding Learned Representations and Action Collapse in Visual Reinforcement Learning</li>
<li class='p-1'>Mitigating Suboptimality of Deterministic Policy Gradients in Complex Q-functions</li>
<li class='p-1'>ProtoCRL: Prototype-based Network for Continual Reinforcement Learning</li>
<li class='p-1'>Offline Reinforcement Learning with Domain-Unlabeled Data</li>
<li class='p-1'>SPEQ: Offline Stabilization Phases for Efficient Q-Learning in High Update-To-Data Ratio Reinforcement Learning</li>
<li class='p-1'>Offline Reinforcement Learning with Wasserstein Regularization via Optimal Transport Maps</li>
<li class='p-1'>Zero-Shot Reinforcement Learning Under Partial Observability</li>
<li class='p-1'>Adaptive Submodular Policy Optimization</li>
</ol></div>
<div class='bg-rllightblue-50 shadow rounded-lg p-6'>
<h3 class='text-xl font-semibold mb-3 text-blue m-2 p-2'>Track 2: RL from human feedback, Imitation Learning</h3>
<ol class='list-decimal p-2 m-2'>
<li class='p-1'>Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback</li>
<li class='p-1'>Nonparametric Policy Improvement in Continuous Action Spaces via Expert Demonstrations</li>
<li class='p-1'>DisDP: Robust Imitation Learning via Disentangled Diffusion Policies</li>
<li class='p-1'>Mitigating Goal Misgeneralization via Minimax Regret</li>
<li class='p-1'>Modelling human exploration with light-weight meta reinforcement learning algorithms</li>
<li class='p-1'>Towards Improving Reward Design in RL: A Reward Alignment Metric for RL Practitioners</li>
<li class='p-1'>PAC Apprenticeship Learning with Bayesian Active Inverse Reinforcement Learning</li>
<li class='p-1'>Offline Action-Free Learning of Ex-BMDPs by Comparing Diverse Datasets</li>
<li class='p-1'>One Goal, Many Challenges: Robust Preference Optimization Amid Content-Aware and Multi-Source Noise</li>
<li class='p-1'>Goals vs. Rewards: A Comparative Study of Objective Specification Mechanisms</li>
<li class='p-1'>Reward Distance Comparisons Under Transition Sparsity</li>
</ol></div>
<div class='bg-rllightblue-50 shadow rounded-lg p-6'>
<h3 class='text-xl font-semibold mb-3 text-blue m-2 p-2'>Track 3: Hierarchical RL, Planning algorithms</h3>
<ol class='list-decimal p-2 m-2'>
<li class='p-1'>AVID: Adapting Video Diffusion Models to World Models</li>
<li class='p-1'>The Confusing Instance Principle for Online Linear Quadratic Control</li>
<li class='p-1'>Long-Horizon Planning with Predictable Skills</li>
<li class='p-1'>Optimal discounting for offline input-driven MDP</li>
<li class='p-1'>DeepCubeAF: A Foundation Model for Generalizable Pathfinding Heuristics</li>
<li class='p-1'>A Timer-Enforced Hybrid Supervisor for Robust, Chatter-Free Policy Switching</li>
<li class='p-1'>Focused Skill Discovery: Learning to Control Specific State Variables while Minimizing Side Effects</li>
<li class='p-1'>Representation Learning and Skill Discovery with Empowerment</li>
<li class='p-1'>Compositional Instruction Following with Language Models and Reinforcement Learning</li>
<li class='p-1'>Composition and Zero-Shot Transfer with Lattice Structures in Reinforcement Learning</li>
<li class='p-1'>Double Horizon Model-Based Policy Optimization</li>
</ol></div>
<div class='bg-rllightblue-50 shadow rounded-lg p-6'>
<h3 class='text-xl font-semibold mb-3 text-blue m-2 p-2'>Track 4: Evaluation, Benchmarks</h3>
<ol class='list-decimal p-2 m-2'>
<li class='p-1'>Which Experiences Are Influential for RL Agents? Efficiently Estimating The Influence of Experiences</li>
<li class='p-1'>Offline vs. Online Learning in Model-based RL: Lessons for Data Collection Strategies</li>
<li class='p-1'>Multi-Task Reinforcement Learning Enables Parameter Scaling</li>
<li class='p-1'>Benchmarking Massively Parallelized Multi-Task Reinforcement Learning for Robotics Tasks</li>
<li class='p-1'>PufferLib 2.0: Reinforcement Learning at 1M steps/s</li>
<li class='p-1'>Uncovering RL Integration in SSL Loss: Objective-Specific Implications for Data-Efficient RL</li>
<li class='p-1'>Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains</li>
<li class='p-1'>How Should We Meta-Learn Reinforcement Learning Algorithms?</li>
<li class='p-1'>AdaStop: adaptive statistical testing for sound comparisons of Deep RL agents</li>
<li class='p-1'>Mental Modelling of Reinforcement Learning Agents by Language Models</li>
<li class='p-1'>MixUCB: Enhancing Safe Exploration in Contextual Bandits with Human Oversight</li>
</ol></div>
</div>
<h2 class='text-3xl font-bai text-center text-blue m-4 p-4'>Aug 7</h2>
<div class='grid grid-cols-1 md:grid-cols-2 lg:grid-cols-2 gap-4'>
<div class='bg-rllightblue-50 shadow rounded-lg p-6'>
<h3 class='text-xl font-semibold mb-3 text-blue m-2 p-2'>Track 1: Deep RL</h3>
<ol class='list-decimal p-2 m-2'>
<li class='p-1'>Understanding the Effectiveness of Learning Behavioral Metrics in Deep Reinforcement Learning</li>
<li class='p-1'>Impoola: The Power of Average Pooling for Image-based Deep Reinforcement Learning</li>
<li class='p-1'>Eau De $Q$-Network: Adaptive Distillation of Neural Networks in Deep Reinforcement Learning</li>
<li class='p-1'>Disentangling Recognition and Decision Regrets in Image-Based Reinforcement Learning</li>
<li class='p-1'>Make the Pertinent Salient: Task-Relevant Reconstruction for Visual Control with Distractions</li>
<li class='p-1'>Pretraining Decision Transformers with Reward Prediction for In-Context Multi-task Structured Bandit Learning</li>
<li class='p-1'>Sampling from Energy-based Policies using Diffusion</li>
<li class='p-1'>Optimistic critics can empower small actors</li>
<li class='p-1'>Scalable Real-Time Recurrent Learning Using Columnar-Constructive Networks</li>
<li class='p-1'>AGaLiTe: Approximate Gated Linear Transformers for Online Reinforcement Learning</li>
<li class='p-1'>Deep Reinforcement Learning with Gradient Eligibility Traces</li>
</ol></div>
<div class='bg-rllightblue-50 shadow rounded-lg p-6'>
<h3 class='text-xl font-semibold mb-3 text-blue m-2 p-2'>Track 2: Social and economic aspects, Neuroscience and cognitive science</h3>
<ol class='list-decimal p-2 m-2'>
<li class='p-1'>Pareto Optimal Learning from Preferences with Hidden Context</li>
<li class='p-1'>When and Why Hyperbolic Discounting Matters for Reinforcement Learning Interventions</li>
<li class='p-1'>Reinforcement Learning from Human Feedback with High-Confidence Safety Guarantees</li>
<li class='p-1'>Towards Large Language Models that Benefit for All: Benchmarking Group Fairness in Reward Models</li>
<li class='p-1'>Reinforcement Learning for Human-AI Collaboration via Probabilistic Intent Inference</li>
<li class='p-1'>High-Confidence Policy Improvement from Human Feedback</li>
<li class='p-1'>Building Sequential Resource Allocation Mechanisms without Payments</li>
<li class='p-1'>From Explainability to Interpretability: Interpretable Reinforcement Learning Via Model Explanations</li>
<li class='p-1'>Learning Fair Pareto-Optimal Policies in Multi-Objective Reinforcement Learning</li>
<li class='p-1'>AI in a vat: Fundamental limits of efficient world modelling for safe agent sandboxing</li>
</ol></div>
<div class='bg-rllightblue-50 shadow rounded-lg p-6'>
<h3 class='text-xl font-semibold mb-3 text-blue m-2 p-2'>Track 3: Exploration</h3>
<ol class='list-decimal p-2 m-2'>
<li class='p-1'>Uncertainty Prioritized Experience Replay</li>
<li class='p-1'>Pure Exploration for Constrained Best Mixed Arm Identification with a Fixed Budget</li>
<li class='p-1'>Quantitative Resilience Modeling for Autonomous Cyber Defense</li>
<li class='p-1'>Learning to Explore in Diverse Reward Settings via Temporal-Difference-Error Maximization</li>
<li class='p-1'>Syllabus: Portable Curricula for Reinforcement Learning Agents</li>
<li class='p-1'>Exploration-Free Reinforcement Learning with Linear Function Approximation</li>
<li class='p-1'>Value Bonuses using Ensemble Errors for Exploration in Reinforcement Learning</li>
<li class='p-1'>Intrinsically Motivated Discovery of Temporally Abstract Graph-based Models of the World</li>
<li class='p-1'>An Optimisation Framework for Unsupervised Environment Design</li>
<li class='p-1'>Epistemically-guided forward-backward exploration</li>
<li class='p-1'>RLeXplore: Accelerating Research in Intrinsically-Motivated Reinforcement Learning</li>
</ol></div>
<div class='bg-rllightblue-50 shadow rounded-lg p-6'>
<h3 class='text-xl font-semibold mb-3 text-blue m-2 p-2'>Track 4: Theoretical RL, Bandit algorithms</h3>
<ol class='list-decimal p-2 m-2'>
<li class='p-1'>A Finite-Time Analysis of Distributed Q-Learning</li>
<li class='p-1'>Finite-Time Analysis of Minimax Q-Learning</li>
<li class='p-1'>Improved Regret Bound for Safe Reinforcement Learning via Tighter Cost Pessimism and Reward Optimism</li>
<li class='p-1'>Non-Stationary Latent Auto-Regressive Bandits</li>
<li class='p-1'>A Finite-Sample Analysis of an Actor-Critic Algorithm for Mean-Variance Optimization in a Discounted MDP</li>
<li class='p-1'>Leveraging priors on distribution functions for multi-arm bandits</li>
<li class='p-1'>Multi-task Representation Learning for Fixed Budget Pure-Exploration in Linear and Bilinear Bandits</li>
<li class='p-1'>On Slowly-varying Non-stationary Bandits</li>
<li class='p-1'>Empirical Bound Information-Directed Sampling</li>
<li class='p-1'>Thompson Sampling for Constrained Bandits</li>
<li class='p-1'>Achieving Limited Adaptivity for Multinomial Logistic Bandits</li>
</ol></div>
</div>
<h2 class='text-3xl font-bai text-center text-blue m-4 p-4'>Aug 8</h2>
<div class='grid grid-cols-1 md:grid-cols-2 lg:grid-cols-2 gap-4'>
<div class='bg-rllightblue-50 shadow rounded-lg p-6'>
<h3 class='text-xl font-semibold mb-3 text-blue m-2 p-2'>Track 1: RL algorithms, Deep RL</h3>
<ol class='list-decimal p-2 m-2'>
<li class='p-1'>Bayesian Meta-Reinforcement Learning with Laplace Variational Recurrent Networks</li>
<li class='p-1'>Cascade - A sequential ensemble method for continuous control tasks</li>
<li class='p-1'>HANQ: Hypergradients, Asymmetry, and Normalization for Fast and Stable Deep $Q$-Learning</li>
<li class='p-1'>Rectifying Regression in Reinforcement Learning</li>
<li class='p-1'>Efficient Morphology-Aware Policy Transfer to New Embodiments</li>
<li class='p-1'>Finer Behavioral Foundation Models via Auto-Regressive Features and Advantage Weighting</li>
<li class='p-1'>Concept-Based Off-Policy Evaluation</li>
<li class='p-1'>Multiple-Frequencies Population-Based Training</li>
<li class='p-1'>AVG-DICE: Stationary Distribution Correction by Regression</li>
<li class='p-1'>Iterated Q-Network: Beyond One-Step Bellman Updates in Deep Reinforcement Learning</li>
</ol></div>
<div class='bg-rllightblue-50 shadow rounded-lg p-6'>
<h3 class='text-xl font-semibold mb-3 text-blue m-2 p-2'>Track 2: Applied RL</h3>
<ol class='list-decimal p-2 m-2'>
<li class='p-1'>Action Mapping for Reinforcement Learning in Continuous Environments with Constraints</li>
<li class='p-1'>Chargax: A JAX Accelerated EV Charging Simulator</li>
<li class='p-1'>WOFOSTGym: A Crop Simulator for Learning Annual and Perennial Crop Management Strategies</li>
<li class='p-1'>Drive Fast, Learn Faster: On-Board RL for High Performance Autonomous Racing</li>
<li class='p-1'>Multi-Agent Reinforcement Learning for Inverse Design in Photonic Integrated Circuits</li>
<li class='p-1'>Gaussian Process Q-Learning for Finite-Horizon Markov Decision Process</li>
<li class='p-1'>Hybrid Classical/RL Local Planner for Ground Robot Navigation</li>
<li class='p-1'>V-Max: Making RL Practical for Autonomous Driving</li>
<li class='p-1'>Shaping Laser Pulses with Reinforcement Learning</li>
<li class='p-1'>Learning Sub-Second Routing Optimization in Computer Networks requires Packet-Level Dynamics</li>
</ol></div>
<div class='bg-rllightblue-50 shadow rounded-lg p-6'>
<h3 class='text-xl font-semibold mb-3 text-blue m-2 p-2'>Track 3: Multi-agent RL</h3>
<ol class='list-decimal p-2 m-2'>
<li class='p-1'>Reinforcement Learning for Finite Space Mean-Field Type Game</li>
<li class='p-1'>Collaboration Promotes Group Resilience in Multi-Agent RL</li>
<li class='p-1'>Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models</li>
<li class='p-1'>Hierarchical Multi-agent Reinforcement Learning for Cyber Network Defense</li>
<li class='p-1'>Efficient Information Sharing for Training Decentralized Multi-Agent World Models</li>
<li class='p-1'>Adaptive Reward Sharing to Enhance Learning in the Context of Multiagent Teams</li>
<li class='p-1'>Seldonian Reinforcement Learning for Ad Hoc Teamwork</li>
<li class='p-1'>Joint-Local Grounded Action Transformation for Sim-to-Real Transfer in Multi-Agent Traffic Control</li>
<li class='p-1'>TransAM: Transformer-Based Agent Modeling for Multi-Agent Systems via Local Trajectory Encoding</li>
<li class='p-1'>PEnGUiN: Partially Equivariant Graph NeUral Networks for Sample Efficient MARL</li>
<li class='p-1'>Human-Level Competitive Pokémon via Scalable Offline Reinforcement Learning with Transformers</li>
</ol></div>
<div class='bg-rllightblue-50 shadow rounded-lg p-6'>
<h3 class='text-xl font-semibold mb-3 text-blue m-2 p-2'>Track 4: Foundations</h3>
<ol class='list-decimal p-2 m-2'>
<li class='p-1'>Effect of a slowdown correlated to the current state of the environment on an asynchronous learning architecture</li>
<li class='p-1'>Average-Reward Soft Actor-Critic</li>
<li class='p-1'>Your Learned Constraint is Secretly a Backward Reachable Tube</li>
<li class='p-1'>Recursive Reward Aggregation</li>
<li class='p-1'>On the Effect of Regularization in Policy Mirror Descent</li>
<li class='p-1'>Investigating the Utility of Mirror Descent in Off-policy Actor-Critic</li>
<li class='p-1'>Rethinking the Foundations for Continual Reinforcement Learning</li>
<li class='p-1'>An Analysis of Action-Value Temporal-Difference Methods That Learn State Values</li>
<li class='p-1'>Reinforcement Learning with Adaptive Temporal Discounting</li>
<li class='p-1'>Learning in complex action spaces without policy gradients</li>
</ol></div>
</div>
          
          </div>
        </div>
      </div>

      <!-- Load menu functionality -->
      <script src="menu.js"></script>
</body>

</html>